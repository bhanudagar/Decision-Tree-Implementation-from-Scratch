{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df, test_df = train_test_split(df, test_size_proportion = 0.2)\n",
    "tree = decision_tree_algorithm(train_df)\n",
    "accuracy = calculate_accuracy(test_df, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "\n",
    "#takes care that out plots are shown in this notebook only\n",
    "%matplotlib inline \n",
    "\n",
    "#takes care that the tree that we create is easy to read and understand\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### format of the data\n",
    "1. last column of the data frame must contain the label and it must also be called \"label\"\n",
    "2.  there should be no missing values in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\", header = None)\n",
    "df.columns = ['sl', 'sw', 'pl', 'pw', 'flower_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>flower_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sl   sw   pl   pw  flower_type\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {\"flower_type\" : \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sl   sw   pl   pw        label\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train-test-split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    #We'll check if the test_size is in proportion or a number\n",
    "\n",
    "    if(isinstance(test_size, float)):\n",
    "        test_size = test_size * len(df)\n",
    "        test_size = round(test_size)\n",
    "\n",
    "    #it creates a list of all the indexes as we will split based on random indexes. we created this list because\n",
    "    #the sample function below can operate on lists only.\n",
    "    indices = df.index.tolist()\n",
    "\n",
    "    #we need to select random indices from it.\n",
    "    #k is the number of elements that we want to sample from this population.\n",
    "    test_indices = random.sample(population = indices, k = test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.seed() makes sure that we get the same random numbers when we run the function\n",
    "# random.seed(0)\n",
    "train_df, test_df = train_test_split(df, test_size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.9, 3.0, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.7, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [4.6, 3.1, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.6, 1.4, 0.2, 'Iris-setosa']], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_df.values\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pure ? \n",
    "#### it checks if a certain partition of our data contains just one class(pure) or several classes(not pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:,-1]\n",
    "\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if(len(unique_classes) == 1):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_purity(train_df[train_df.pw <= 0.8].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    #check_purity function already ran when this function runs.\n",
    "\n",
    "    label_column = data[:,-1]\n",
    "    \n",
    "    ## this can be enough if the data is pure.\n",
    "    # classification = label_column[0]\n",
    "\n",
    "    \n",
    "    # But there are some cases where we want to classify our data \n",
    "    #before it is pure yet. For example, we want a minimum number of data points. And if dont have them, we will classify that data.\n",
    "    #based on either majority or random basis.\n",
    "    \n",
    "    #HERE WE ARE CLASSIFYING THEM BASED UPON THE MAJORITY ELEMENT.\n",
    "    \n",
    "    #to see which class appears the most, \n",
    "    \n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts = True)\n",
    "\n",
    "    #to get index of largest value of count\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    #returns the class that \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sl   sw   pl   pw        label\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    \n",
    "    #keys will be the indices of the columns\n",
    "\n",
    "    potential_splits = {}\n",
    "\n",
    "    #we just need the number of columns, so we write underscore'_' for row part\n",
    "\n",
    "    _, n_columns = data.shape\n",
    "\n",
    "    #to iterate over the columns, we write this loop and n_columns - 1 because last column is for label\n",
    "    for column_index in range(n_columns - 1):\n",
    "\n",
    "        #we will create one entry in our potential split dictionary and it will be an empty list\n",
    "        #in which we will append our potential splits\n",
    "        potential_splits[column_index] = []\n",
    "\n",
    "        #we will consider every line between any two values as potential splits\n",
    "        # so, to get those potential splits, we will need first of all, all the values for that particular feature (or column)\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        potential_splits[column_index] = unique_values\n",
    "        \n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "# the dictionary potential_splits will have the columns as keys, and their values will be \n",
    "#all the unique values inside that particular column\n",
    "\n",
    "# potential_split = {'pw':[0.1, 0.2],\n",
    "                    # 'pl':[4, 5, 6]} iss type se hoga\n",
    "    \n",
    "# ye sabhi potential splits hain mtlb kya kya ho sakte hain splits, best split nikaalenge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_splits = get_potential_splits(train_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking if this potential split makes any sense. therefore, we'll create a scatter plot using seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7fd81c5b4c10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 751.5x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(data = train_df, x = \"pw\", y = \"pl\", hue = \"label\", \n",
    "           fit_reg = False, height = 6, aspect = 1.5)\n",
    "\n",
    "# potential split based upon column number 3, that is pw\n",
    "plt.vlines(x = potential_splits[3], ymin = 1, ymax = 7)\n",
    "\n",
    "# potential split based upon column number 2\n",
    "# plt.hlines(y = potential_splits[2], xmin = 0, xmax = 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after potential split, humaare paas data hoga split karne k liye\n",
    "# data_below the split(left) and data_above the split(right)\n",
    "\n",
    "def split_data(data, split_column, split_value):\n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    #to see which values are below and we'll use boolean indexing\n",
    "    \n",
    "    #Feature_types is a global variable list. usme sabhi columns k baare mein likha hai, \n",
    "    #whether it is continuous or discrete\n",
    "    #, jo humein batayega ki feature humara continuous hai ya discrete\n",
    "    \n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values > split_value]\n",
    "    #discrete\n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "        \n",
    "    return data_below, data_above\n",
    "    #first numpy2d array should contain all the datapoints tht are below the split and vice versa\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowest Overall Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    #Entropy = \n",
    "    #SUM (pi * (-log base2 (pi)))\n",
    "\n",
    "    label_column = data[:, -1]\n",
    "\n",
    "    _, counts = np.unique(label_column, return_counts = True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    # Overall entropy = sum(pj * entropy)\n",
    "\n",
    "    #we need to know the p values, and for p values we need how many data points are there in our data\n",
    "\n",
    "    n_data_points = len(data_below) + len(data_above)\n",
    "\n",
    "    p_data_below = len(data_below) / n_data_points\n",
    "\n",
    "    p_data_above = len(data_above) / n_data_points\n",
    "\n",
    "    overall_entropy = ((p_data_below) * calculate_entropy(data_below)\n",
    "                       + p_data_above * calculate_entropy(data_above))\n",
    "\n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "\n",
    "    #create a variable and set it to arbitrary high value \n",
    "    overall_entropy = 999\n",
    "\n",
    "    #then the function should loop over all the potential splits\n",
    "    #calculate the overall entropy that will be the result of particular split\n",
    "    #and then, if the overall entropy of that particular split is lower\n",
    "    #than our intial overall entropy, then we are gonna consider the parameters of that split\n",
    "    #into our best fit column and best split value \n",
    "\n",
    "\n",
    "    for column_index in potential_splits:\n",
    "        \n",
    "#         print(COLUMN_HEADERS[column_index], \"-\", len(np.unique(data[:, column_index])))\n",
    "        \n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column = column_index, \n",
    "                                                split_value = value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential_splits = get_potential_splits(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine_best_split(data, potential_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine type of Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    feature_types = []\n",
    "    n_unique_values_threshold = 15 #because continuous features contain a large number of values. \n",
    "    \n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        \n",
    "        example_value = unique_values[0]\n",
    "        \n",
    "        if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_threshold):\n",
    "            feature_types.append(\"categorical\")\n",
    "        else:\n",
    "            feature_types.append(\"continuous\")\n",
    "    \n",
    "    \n",
    "    return feature_types #categorical or continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Explanation of the above function :- \n",
    "- if there is a string in a feature, then the feature is categorical feature catergorical feature can also have an integer.\n",
    "- if feature has float, then it is continuous.\n",
    "\n",
    "- How to determine the feature is categorical or continuous ?\n",
    "    - if number, then we have to see how many unique values there are in that column.\n",
    "    - continuous features can take infinite values.\n",
    "    - So, generally, continuous features will have many more unique values than categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>sw</th>\n",
       "      <th>pl</th>\n",
       "      <th>pw</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sl   sw   pl   pw        label\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sl - continuous\n",
      "sw - continuous\n",
      "pl - continuous\n",
      "pw - continuous\n",
      "label - categorical\n"
     ]
    }
   ],
   "source": [
    "feature_types = determine_type_of_feature(df)\n",
    "i = 0\n",
    "for column in df.columns:\n",
    "    print(column, \"-\", feature_types[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sl', 'sw', 'pl', 'pw', 'label'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we wont pass in the numpy 2d array instead we'll pass in dataframe\n",
    "\n",
    "#min_samples is pruning\n",
    "def decision_tree_algorithm(df, counter = 0, min_samples = 2, max_depth = 5):\n",
    "    # we need to convert this dataframe into a numpy 2d array in first call of the function\n",
    "    #this is a recursive function\n",
    "    \n",
    "    #data preparation part\n",
    "    if counter == 0:\n",
    "        #making column_header as a global variable\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    #base case 1\n",
    "    if check_purity(data) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    \n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        counter += 1\n",
    "        \n",
    "        #helper functions\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        #entropy\n",
    "        entropy = calculate_overall_entropy(data_below, data_above)\n",
    "        \n",
    "        \n",
    "        # check for empty data\n",
    "        if len(data_below) == 0 or len(data_above) == 0:\n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "        \n",
    "        \n",
    "        #now we can think about how are we going to build the tree\n",
    "        #instantiate sub-tree\n",
    "        \n",
    "        #determine question\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        \n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "        \n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "        \n",
    "        #feature is categorical\n",
    "        else:\n",
    "            question = \"{} = {}\".format(feature_name, split_value)\n",
    "            \n",
    "        \n",
    "        #instantiate sub-tree\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        #find answers (recursion part)\n",
    "        \n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "            \n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pw <= 0.6': ['Iris-setosa',\n",
      "               {'pl <= 4.8': [{'pw <= 1.6': ['Iris-versicolor',\n",
      "                                             'Iris-virginica']},\n",
      "                              'Iris-virginica']}]}\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_algorithm(train_df, max_depth = 3)\n",
    "pprint(tree, width = 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl                  6.3\n",
       "sw                  2.7\n",
       "pl                  4.9\n",
       "pw                  1.8\n",
       "label    Iris-virginica\n",
       "Name: 123, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = test_df.iloc[10]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is to predict the output for our test dataframe\n",
    "\n",
    "# example is the input sample and tree is the decision tree algorithm that we will apply on our input to predict the output\n",
    "\n",
    "\n",
    "def classify_example(example, tree):\n",
    "    # it has a base case and a recursion function\n",
    "    \n",
    "    #base case is if the answer to our question is a class, that is, it it not a dictionary\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split()\n",
    "\n",
    "    # ask question\n",
    "    \n",
    "    if comparison_operator == \"<=\":\n",
    "    \n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "            \n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    #base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "\n",
    "    #recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-virginica'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_example(example, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "    # we create 2 columns in the df dataframe, 1st column for classification, \n",
    "    # 2nd for if the classification is correct or not. we can use it to calculate the actual accuracy as well\n",
    "    # we can see where there is misclassification and if yes, why ?\n",
    "    \n",
    "    df[\"classification\"] = df.apply(classify_example, axis = 1, args = (tree, ))\n",
    "    \n",
    "    # if the classification is correct or not\n",
    "    df[\"classification_correct\"] = df.classification == df.label\n",
    "    #calculating mean of the classification_correct column for accuracy\n",
    "    accuracy = df.classification_correct.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(test_df, tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pw <= 0.6': ['Iris-setosa',\n",
      "               {'pw <= 1.7': [{'pl <= 4.9': [{'pw <= 1.6': ['Iris-versicolor',\n",
      "                                                            'Iris-virginica']},\n",
      "                                             {'pw <= 1.5': ['Iris-virginica',\n",
      "                                                            {'pl <= 5.1': ['Iris-versicolor',\n",
      "                                                                           'Iris-virginica']}]}]},\n",
      "                              'Iris-virginica']}]}\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "tree = decision_tree_algorithm(train_df, max_depth = )\n",
    "accuracy = calculate_accuracy(test_df, tree)\n",
    "\n",
    "pprint(tree)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level = 0\n",
    "# for i in tree:\n",
    "    \n",
    "#     feature_name, comparison, value = i.split()\n",
    "    \n",
    "#     print(\"Level \", level)\n",
    "#     split_column, split_value = determine_best_split(data, potential_splits)\n",
    "#     data_below, data_above = split_data(data, split_column, split_value)\n",
    "    \n",
    "#     print(\"Count of\", comparison, value, 'values =', len(data_below)) \n",
    "#     print(\"Count of\", comparison, value, 'values =', len(data_above))\n",
    "    \n",
    "#     entropy = calculate_overall_entropy(data_below, data_above)\n",
    "    \n",
    "#     print(\"Current Entropy is :\",entropy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
